{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from util import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from losses import *\n",
    "from flags_and_variables import *\n",
    "from encode_boxes import *\n",
    "from fcos import *\n",
    "from tensorpack.tfutils.optimizer import AccumGradOptimizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyramid_dict = get_fpn_output(inputs,is_training=True,is_trainable=True)\n",
    "centerness_output,classes_output,boxes_output = get_network_output(feature_layer_list,pyramid_dict,feature_size)\n",
    "centerness_output = tf.concat(centerness_output,axis=1)\n",
    "classes_output = tf.concat(classes_output,axis=1)\n",
    "boxes_output = tf.concat(boxes_output,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training part\n",
    "centerness_output_test = centerness_output\n",
    "classes_output_test = classes_output\n",
    "boxes_output_test = boxes_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###testing part\n",
    "centerness_pred = tf.sigmoid(centerness_output)\n",
    "classes_pred = tf.sigmoid(classes_output)\n",
    "localization_pred = boxes_output\n",
    "_scores,_classes,_boxes = predict_outputs(centerness_pred,classes_pred,localization_pred,feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4)\n",
      "(?, 1)\n"
     ]
    }
   ],
   "source": [
    "#focal loss\n",
    "focal_losses = focal_loss(classes,classes_output_test,state)\n",
    "IOU_losses = iou_loss(boxes, boxes_output_test,state,centerness)\n",
    "centerness_losses = centerness_loss(centerness, centerness_output_test,state)\n",
    "regular_loss = tf.losses.get_regularization_loss()/tf.reduce_sum(state)\n",
    "total_losses = focal_losses+IOU_losses+centerness_losses+regular_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1219 16:05:07 @gradproc.py:79]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m No gradient w.r.t 3 trainable variables: resnet_v2_50/postnorm/gamma, resnet_v2_50/postnorm/beta, resnet_v2_50/logits/biases\n"
     ]
    }
   ],
   "source": [
    "tf.summary.scalar('scala/total_losses',total_losses)\n",
    "tf.summary.scalar('scala/focal_losses',focal_losses)\n",
    "tf.summary.scalar('scala/IOU_losses',IOU_losses)\n",
    "tf.summary.scalar('scala/centerness_losses',centerness_losses)\n",
    "tf.summary.scalar('scala/reg_loss',regular_loss)\n",
    "ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n",
    "if ckpt:\n",
    "    start_step = int(ckpt.split('-')[-1])\n",
    "else:\n",
    "    start_step = 0  \n",
    "    \n",
    "with tf.variable_scope(\"optimizer\") as scope:\n",
    "    global_step = tf.get_variable(\"step\", [], initializer=tf.constant_initializer(start_step), trainable=False)\n",
    "#     rate = tf.train.exponential_decay(FLAGS.learning_rate, global_step, decay_steps=20000, decay_rate=0.1, staircase=True)\n",
    "    rate = FLAGS.learning_rate\n",
    "    update_opts = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies([tf.group(update_opts)]):\n",
    "        adam_opt = tf.train.AdamOptimizer(rate)\n",
    "#         momentum_opt = tf.train.MomentumOptimizer(rate,momentum=0.9)\n",
    "#         SGD_opt = tf.train.GradientDescentOptimizer(learning_rate=rate)\n",
    "        train_opt = AccumGradOptimizer(adam_opt, niter=iter_size).minimize(total_losses,global_step=global_step)\n",
    "tf.summary.scalar('scala/learning_rate',rate)\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_2012_train = get_path_and_annotation('/media/xinje/New Volume/VOC07&12/VOC2012/train_2012.txt')\n",
    "annotation_2007_train = get_path_and_annotation('/media/xinje/New Volume/VOC07&12/VOC2007/train/train_2007.txt')\n",
    "annotation_train = annotation_2012_train +annotation_2007_train\n",
    "\n",
    "annotation_2012_test = get_path_and_annotation('/media/xinje/New Volume/VOC07&12/VOC2012/val_2012.txt')\n",
    "annotation_2007_test = get_path_and_annotation('/media/xinje/New Volume/VOC07&12/VOC2007/test/test_2007.txt')\n",
    "annotation_test = annotation_2012_test +annotation_2007_test\n",
    "\n",
    "train_iter = read_data(annotation_train,FLAGS.batch_size,input_shape=(800,1024),is_random=True,is_crop=False)\n",
    "test_iter = read_data(annotation_test,1,input_shape=(800,1024),is_random=False,is_crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /media/xinje/New Volume/fcos/resnet_v2_50_giou/FCOS--1700\n",
      "Restore from the checkpoint /media/xinje/New Volume/fcos/resnet_v2_50_giou/FCOS--1700\n",
      "Batch: 1701   Current total loss: 1.9021717 focal_loss: 0.25536814 IOU_loss: 1.017626 centerness_loss: 0.6236536\n",
      "Batch: 1702   Current total loss: 1.2343011 focal_loss: 0.22411016 IOU_loss: 0.40348992 centerness_loss: 0.60094416\n",
      "Batch: 1703   Current total loss: 2.0290735 focal_loss: 0.2768147 IOU_loss: 1.1333894 centerness_loss: 0.611671\n",
      "Batch: 1704   Current total loss: 1.671384 focal_loss: 0.18866517 IOU_loss: 0.87526816 centerness_loss: 0.5973361\n",
      "Batch: 1705   Current total loss: 2.672367 focal_loss: 0.35166812 IOU_loss: 1.6845733 centerness_loss: 0.62630665\n",
      "Batch: 1706   Current total loss: 1.433265 focal_loss: 0.27569845 IOU_loss: 0.5533683 centerness_loss: 0.59628254\n",
      "Batch: 1707   Current total loss: 1.5411481 focal_loss: 0.21650228 IOU_loss: 0.7083014 centerness_loss: 0.6087319\n",
      "Batch: 1708   Current total loss: 1.7602941 focal_loss: 0.26886544 IOU_loss: 0.88099676 centerness_loss: 0.6001749\n",
      "Batch: 1709   Current total loss: 1.7604054 focal_loss: 0.25187978 IOU_loss: 0.90858394 centerness_loss: 0.5901666\n",
      "Batch: 1710   Current total loss: 1.1985955 focal_loss: 0.230655 IOU_loss: 0.36623508 centerness_loss: 0.5908362\n",
      "Batch: 1711   Current total loss: 1.1619817 focal_loss: 0.19425388 IOU_loss: 0.36332178 centerness_loss: 0.5957708\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    train_writer = tf.summary.FileWriter(FLAGS.log_dir,sess.graph)\n",
    "#     var_list = [var for var in tf.global_variables() if ('optimizer') not in var.name]\n",
    "    var_list_final = tf.global_variables()\n",
    "\n",
    "    \n",
    "    saver_final = tf.train.Saver(var_list=var_list_final,max_to_keep=5)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n",
    "    if ckpt:\n",
    "        saver_final.restore(sess,ckpt)\n",
    "        print('Restore from the checkpoint {0}'.format(ckpt)) \n",
    "#         exclude = []\n",
    "#         variables_to_restore = tf.contrib.slim.get_variables_to_restore(exclude=exclude)\n",
    "#         tf.train.init_from_checkpoint(ckpt,\n",
    "#                                     {v.name.split(':')[0]: v for v in variables_to_restore})  \n",
    "    else:\n",
    "        print('Train ssd from start')\n",
    "        ckpt = './resnet_v2_50_2017_04_14/resnet_v2_50.ckpt'\n",
    "        exclude = ['resnet_v2_50' + '/logits', 'global_step','output','output2',\"optimizer\",'postnorm']\n",
    "        variables_to_restore = tf.contrib.slim.get_variables_to_restore(exclude=exclude)\n",
    "        saver = tf.train.Saver(var_list=variables_to_restore,max_to_keep=5)\n",
    "        saver.restore(sess,ckpt)\n",
    "        \n",
    "    for i in range(start_step+1,10000000):\n",
    "        if(i%(len(annotation_train)//FLAGS.batch_size)==0):\n",
    "            random.shuffle(annotation_train)\n",
    "            train_iter = read_data(annotation_train,FLAGS.batch_size,input_shape=(800,1024),is_random=True,is_crop=False)\n",
    "        image_batch,annotation_batch,cls_batch = next(train_iter)\n",
    "        #one hot for cls_batch\n",
    "        eye = np.eye(20)\n",
    "        eye = np.concatenate([eye,np.expand_dims(np.zeros_like(eye[0]),axis=0)])\n",
    "        cls_batch = eye[(cls_batch-1).astype(np.int32)].astype(np.float32)\n",
    "        \n",
    "        matched_true_boxes,matched_true_classes,matched_true_centerness = encode_boxes(annotation_batch,cls_batch,feature_size,stride)\n",
    "        feature_state = np.squeeze(matched_true_centerness!=0,axis=-1)\n",
    "        \n",
    "        feed_dict={inputs:image_batch,boxes:matched_true_boxes,classes:matched_true_classes,centerness:matched_true_centerness,state:feature_state}\n",
    "\n",
    "        [_,train_summary,temp_loss,temp_focal_loss,temp_iou_loss,temp_centerness_loss,temp_centerness_output,temp_classes_output,temp_boxes_output] = sess.run([train_opt,merged_summary_op,total_losses,focal_losses,IOU_losses,centerness_losses,centerness_output_test,classes_output_test,boxes_output_test],feed_dict=feed_dict)\n",
    "        real_step = (i-start_step)//iter_size+start_step\n",
    "        if((i-start_step)%iter_size==0):\n",
    "            print('Batch: '+str(real_step)+'   Current total loss: '+str(temp_loss)+' focal_loss: '+str(temp_focal_loss)+' IOU_loss: '+str(temp_iou_loss)+' centerness_loss: '+str(temp_centerness_loss))\n",
    "#             break\n",
    "            train_writer.add_summary(train_summary, real_step)\n",
    "#             break\n",
    "        if((i-start_step)%(iter_size*50)==0 and i!=0):\n",
    "            image_batch,annotation_batch,cls_batch = next(test_iter)\n",
    "            [temp_scores_pred_list,temp_classes_pred_list,temp_localization_pred_list] = sess.run([_scores,_classes,_boxes],feed_dict={inputs:image_batch})\n",
    "            ymin,xmin,ymax,xmax=np.split(temp_localization_pred_list,axis=1,indices_or_sections =4)\n",
    "            ymax[ymax>FLAGS.image_height]=FLAGS.image_height\n",
    "            xmax[xmax>FLAGS.image_width]=FLAGS.image_width\n",
    "            ymin[ymin<0]=0\n",
    "            xmin[xmin<0]=0\n",
    "            plt.hlines(ymin,xmin,xmax,'r')\n",
    "            plt.hlines(ymax,xmin,xmax,'r')\n",
    "            plt.vlines(xmin,ymin,ymax,'r')\n",
    "            plt.vlines(xmax,ymin,ymax,'r')\n",
    "            for i in range(temp_classes_pred_list.shape[0]):\n",
    "                position = ((ymin[i]+ymax[i])/2,(xmin[i]+xmax[i])/2)\n",
    "                plt.text(position[1],position[0],corresponding_dict[temp_classes_pred_list[i]],color='g',size = 15)\n",
    "            plt.imshow(image_batch[0])\n",
    "            plt.show()\n",
    "#             save model for training\n",
    "            saver_final.save(sess,os.path.join(FLAGS.checkpoint_dir,'FCOS-'),global_step=real_step) \n",
    "            #########################save model for inference#############################################\n",
    "#             constant_graph = convert_variables_to_constants(sess, sess.graph_def, ['boxes','scores','classes'])\n",
    "#             with tf.gfile.FastGFile('./model.pb', mode='wb') as f:\n",
    "#                 f.write(constant_graph.SerializeToString())\n",
    "            #####################################################################\n",
    "            print('Model saved !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# learning_rate = 1e-2\n",
    "# Si = tf.Variable(tf.constant(1.0,shape=[5,1],dtype=tf.float32), trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched_true_boxes,matched_true_classes,matched_true_centerness = encode_boxes(annotation_batch,cls_batch,feature_size,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(y_true, y_pred,anchor_state):\n",
    "    \"\"\"\n",
    "    Compute the focal loss given the target tensor and the predicted tensor.\n",
    "    As defined in https://arxiv.org/abs/1708.02002\n",
    "    Args\n",
    "        y_true: Tensor of target data from the generator with shape (B, N, num_classes).\n",
    "        y_pred: Tensor of predicted data from the network with shape (B, N, num_classes).\n",
    "    Returns\n",
    "        The focal loss of y_pred w.r.t. y_true.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"loss/focal\") as scope:\n",
    "        alpha=0.25\n",
    "        gamma=2.0\n",
    "        # compute the focal loss\n",
    "        location_state = anchor_state\n",
    "        labels = y_true\n",
    "        # alpha 参与用于调节正负样本的平衡问题\n",
    "        alpha_factor = tf.ones_like(labels) * alpha\n",
    "        alpha_factor = tf.where(tf.equal(labels, 1), alpha_factor, 1 - alpha_factor)\n",
    "        # focal_weight 用来使置信度较高容易的样本的 loss 比原来小, 而置信度低的难度大的 loss 变化不大\n",
    "        # (1 - 0.99) ** 2 = 1e-4, (1 - 0.9) ** 2 = 1e-2\n",
    "        focal_weight = tf.where(tf.equal(labels, 1), 1 - y_pred, y_pred)\n",
    "        focal_weight = alpha_factor * focal_weight ** gamma\n",
    "        # binary_crossentropy 是  -log(p) y=1 -log(1-p) y=others, 那么论文中统一的用 -log(pt) 来表示\n",
    "        #cls_loss = focal_weight * tf.nn.sigmoid_cross_entropy_with_logits(labels=labels,logits=y_pred)\n",
    "        cls_loss = focal_weight * tf.keras.backend.binary_crossentropy(target=labels,output=y_pred)\n",
    "        # compute the normalizer: the number of positive anchors\n",
    "        normalizer = tf.where(tf.equal(location_state, 1))\n",
    "        normalizer = tf.cast(tf.shape(normalizer)[0], tf.float32)\n",
    "        normalizer = tf.maximum(1.0, normalizer)\n",
    "        loss = tf.reduce_sum(cls_loss) / normalizer\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iou_loss(y_true, y_pred,location_state,centerness):\n",
    "    with tf.variable_scope(\"loss/iou\") as scope:\n",
    "        # pos location\n",
    "        indices = tf.where(tf.equal(location_state, 1))\n",
    "    #     print(indices.shape)\n",
    "        if tf.size(indices) == 0:\n",
    "            return tf.constant(0.0)\n",
    "        y_regr_pred = tf.gather_nd(y_pred, indices)\n",
    "    #     print(y_regr_pred.shape)\n",
    "        y_regr_true = tf.gather_nd(y_true, indices)\n",
    "        y_centerness_true = tf.gather_nd(centerness,indices)\n",
    "\n",
    "        # (num_pos, )\n",
    "        pred_top = y_regr_pred[:, 0]\n",
    "        pred_bottom = y_regr_pred[:, 1]\n",
    "        pred_left = y_regr_pred[:, 2]\n",
    "        pred_right = y_regr_pred[:, 3]\n",
    "\n",
    "        # (num_pos, )\n",
    "        target_top = y_regr_true[:, 0]\n",
    "        target_bottom = y_regr_true[:, 1]\n",
    "        target_left = y_regr_true[:, 2]\n",
    "        target_right = y_regr_true[:, 3]\n",
    "\n",
    "        target_area = (target_left + target_right) * (target_top + target_bottom)\n",
    "        pred_area = (pred_left + pred_right) * (pred_top + pred_bottom)\n",
    "        w_intersect = tf.minimum(pred_left, target_left) + tf.minimum(pred_right, target_right)\n",
    "        h_intersect = tf.minimum(pred_bottom, target_bottom) + tf.minimum(pred_top, target_top)\n",
    "\n",
    "        g_w_intersect = tf.maximum(pred_left, target_left) + tf.maximum(pred_right, target_right)\n",
    "        g_h_intersect = tf.maximum(pred_bottom, target_bottom) + tf.maximum(pred_top, target_top)\n",
    "        ac_union = g_w_intersect * g_h_intersect\n",
    "        euclidean_distance = tf.pow((-target_left + target_right)/2 -(-pred_left + pred_right)/2,2) + tf.pow((-target_top + target_bottom)/2 -(-pred_top + pred_bottom)/2,2)\n",
    "        area_intersect = w_intersect * h_intersect\n",
    "        area_union = target_area + pred_area - area_intersect\n",
    "        ious = (area_intersect) / (area_union+1e-8)\n",
    "        dious = 1-ious+(euclidean_distance/tf.pow(ac_union+1e-8,2))\n",
    "        # (num_pos, )\n",
    "        #losses = tf.reduce_sum(losses * y_centerness_true) / (tf.reduce_sum(y_centerness_true) + 1e-6)\n",
    "\n",
    "        losses =  tf.reduce_mean(dious)\n",
    "    return losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
