{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from util import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from losses import *\n",
    "from flags_and_variables import *\n",
    "from encode_boxes import *\n",
    "from fcos import *\n",
    "from tensorpack.tfutils.optimizer import AccumGradOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyramid_dict = get_fpn_output(inputs,is_training=True,is_trainable=True)\n",
    "centerness_output,classes_output,boxes_output = get_network_output(feature_layer_list,pyramid_dict,feature_size)\n",
    "centerness_output = tf.concat(centerness_output,axis=1)\n",
    "classes_output = tf.concat(classes_output,axis=1)\n",
    "boxes_output = tf.concat(boxes_output,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###testing part\n",
    "centerness_output_test = centerness_output\n",
    "classes_output_test = classes_output\n",
    "boxes_output_test = boxes_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4)\n",
      "(?, 1)\n"
     ]
    }
   ],
   "source": [
    "#focal loss\n",
    "focal_losses = focal_loss(classes,classes_output_test,state)\n",
    "IOU_losses = iou_loss(boxes, boxes_output_test,state,centerness)\n",
    "centerness_losses = centerness_loss(centerness, centerness_output_test,state)\n",
    "regular_loss = tf.losses.get_regularization_loss()/tf.reduce_sum(state)\n",
    "total_losses = focal_losses+IOU_losses+centerness_losses+regular_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1218 13:34:59 @gradproc.py:79]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m No gradient w.r.t 3 trainable variables: resnet_v2_50/postnorm/gamma, resnet_v2_50/postnorm/beta, resnet_v2_50/logits/biases\n"
     ]
    }
   ],
   "source": [
    "tf.summary.scalar('scala/total_losses',total_losses)\n",
    "tf.summary.scalar('scala/focal_losses',focal_losses)\n",
    "tf.summary.scalar('scala/IOU_losses',IOU_losses)\n",
    "tf.summary.scalar('scala/centerness_losses',centerness_losses)\n",
    "tf.summary.scalar('scala/reg_loss',regular_loss)\n",
    "ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n",
    "if ckpt:\n",
    "    start_step = int(ckpt.split('-')[-1])\n",
    "else:\n",
    "    start_step = 0  \n",
    "    \n",
    "with tf.variable_scope(\"optimizer\") as scope:\n",
    "    global_step = tf.get_variable(\"step\", [], initializer=tf.constant_initializer(start_step), trainable=False)\n",
    "#     rate = tf.train.exponential_decay(FLAGS.learning_rate, global_step, decay_steps=20000, decay_rate=0.1, staircase=True)\n",
    "    rate = FLAGS.learning_rate\n",
    "    update_opts = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies([tf.group(update_opts)]):\n",
    "        adam_opt = tf.train.AdamOptimizer(rate)\n",
    "#         momentum_opt = tf.train.MomentumOptimizer(rate,momentum=0.9)\n",
    "#         SGD_opt = tf.train.GradientDescentOptimizer(learning_rate=rate)\n",
    "        train_opt = AccumGradOptimizer(adam_opt, niter=20).minimize(total_losses,global_step=global_step)\n",
    "tf.summary.scalar('scala/learning_rate',rate)\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = get_path_and_annotation('/media/xinje/New Volume/VOC07&12/VOC2007/train/train_OCR.txt')\n",
    "train_iter = read_data(annotation,FLAGS.batch_size,input_shape=(800,1024),is_random=False,is_crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /media/xinje/New Volume/fcos/resnet_v2_50_freezed_backbone/FCOS--103950\n",
      "Restore from the checkpoint /media/xinje/New Volume/fcos/resnet_v2_50_freezed_backbone/FCOS--103950\n",
      "Batch: 103951   Current total loss: 1.4313412 focal_loss: 0.3592141 IOU_loss: 0.45115155 centerness_loss: 0.6144537\n",
      "Batch: 103952   Current total loss: 1.3658442 focal_loss: 0.29801068 IOU_loss: 0.4579797 centerness_loss: 0.604524\n",
      "Batch: 103953   Current total loss: 1.4545883 focal_loss: 0.34587404 IOU_loss: 0.48839575 centerness_loss: 0.6175157\n",
      "Batch: 103954   Current total loss: 1.2942506 focal_loss: 0.28325126 IOU_loss: 0.41127637 centerness_loss: 0.5953279\n",
      "Batch: 103955   Current total loss: 1.248504 focal_loss: 0.341007 IOU_loss: 0.32677194 centerness_loss: 0.5720355\n",
      "Batch: 103956   Current total loss: 1.328084 focal_loss: 0.33132386 IOU_loss: 0.39805627 centerness_loss: 0.59419775\n",
      "Batch: 103957   Current total loss: 1.3502452 focal_loss: 0.2694814 IOU_loss: 0.47417763 centerness_loss: 0.6039537\n",
      "Batch: 103958   Current total loss: 1.3373543 focal_loss: 0.27330658 IOU_loss: 0.44981834 centerness_loss: 0.60952026\n",
      "Batch: 103959   Current total loss: 1.5252539 focal_loss: 0.37502235 IOU_loss: 0.52487046 centerness_loss: 0.62084824\n",
      "Batch: 103960   Current total loss: 1.269171 focal_loss: 0.3129724 IOU_loss: 0.36247802 centerness_loss: 0.59038436\n",
      "Batch: 103961   Current total loss: 1.195142 focal_loss: 0.24980818 IOU_loss: 0.3414904 centerness_loss: 0.5992485\n",
      "Batch: 103962   Current total loss: 1.669459 focal_loss: 0.47275847 IOU_loss: 0.5769639 centerness_loss: 0.6174684\n",
      "Batch: 103963   Current total loss: 1.3144686 focal_loss: 0.30141482 IOU_loss: 0.40951437 centerness_loss: 0.59966636\n",
      "Batch: 103964   Current total loss: 1.3510787 focal_loss: 0.2967396 IOU_loss: 0.450386 centerness_loss: 0.6020636\n",
      "Batch: 103965   Current total loss: 1.2413019 focal_loss: 0.2846758 IOU_loss: 0.35926348 centerness_loss: 0.5931968\n",
      "Batch: 103966   Current total loss: 1.5314999 focal_loss: 0.4501795 IOU_loss: 0.46417165 centerness_loss: 0.614796\n",
      "Batch: 103967   Current total loss: 1.2863001 focal_loss: 0.292486 IOU_loss: 0.39113823 centerness_loss: 0.5994495\n",
      "Batch: 103968   Current total loss: 1.2514849 focal_loss: 0.275805 IOU_loss: 0.36431468 centerness_loss: 0.605034\n",
      "Batch: 103969   Current total loss: 1.2892929 focal_loss: 0.27530882 IOU_loss: 0.4135507 centerness_loss: 0.5959671\n",
      "Batch: 103970   Current total loss: 1.1243159 focal_loss: 0.26564014 IOU_loss: 0.27929264 centerness_loss: 0.56859076\n",
      "Batch: 103971   Current total loss: 1.2928245 focal_loss: 0.3199071 IOU_loss: 0.36533856 centerness_loss: 0.601326\n",
      "Batch: 103972   Current total loss: 1.2928709 focal_loss: 0.30874047 IOU_loss: 0.36957258 centerness_loss: 0.608419\n",
      "Batch: 103973   Current total loss: 1.3647703 focal_loss: 0.27794147 IOU_loss: 0.47492665 centerness_loss: 0.60925585\n",
      "Batch: 103974   Current total loss: 1.429424 focal_loss: 0.39272866 IOU_loss: 0.4293636 centerness_loss: 0.60413945\n",
      "Batch: 103975   Current total loss: 1.3180833 focal_loss: 0.35741997 IOU_loss: 0.35444316 centerness_loss: 0.59878725\n",
      "Batch: 103976   Current total loss: 1.3570831 focal_loss: 0.3439081 IOU_loss: 0.40959176 centerness_loss: 0.5992754\n",
      "Batch: 103977   Current total loss: 1.4774034 focal_loss: 0.33233005 IOU_loss: 0.5226327 centerness_loss: 0.6190023\n",
      "Batch: 103978   Current total loss: 1.3195497 focal_loss: 0.35136184 IOU_loss: 0.35174647 centerness_loss: 0.6096417\n",
      "Batch: 103979   Current total loss: 1.4448322 focal_loss: 0.31970853 IOU_loss: 0.495946 centerness_loss: 0.6262701\n",
      "Batch: 103980   Current total loss: 1.1762729 focal_loss: 0.2549288 IOU_loss: 0.3155561 centerness_loss: 0.59719694\n",
      "Batch: 103981   Current total loss: 1.2725958 focal_loss: 0.28438815 IOU_loss: 0.38654757 centerness_loss: 0.5966474\n",
      "Batch: 103982   Current total loss: 1.3742316 focal_loss: 0.34178483 IOU_loss: 0.42107382 centerness_loss: 0.6078548\n",
      "Batch: 103983   Current total loss: 1.2587569 focal_loss: 0.26726112 IOU_loss: 0.38766113 centerness_loss: 0.60012275\n",
      "Batch: 103984   Current total loss: 1.325761 focal_loss: 0.2898564 IOU_loss: 0.4284446 centerness_loss: 0.6037206\n",
      "Batch: 103985   Current total loss: 1.4844542 focal_loss: 0.46210453 IOU_loss: 0.40128088 centerness_loss: 0.6163815\n",
      "Batch: 103986   Current total loss: 1.4208232 focal_loss: 0.3347955 IOU_loss: 0.46145332 centerness_loss: 0.61955345\n",
      "Batch: 103987   Current total loss: 1.2437865 focal_loss: 0.25606686 IOU_loss: 0.38359103 centerness_loss: 0.5984707\n",
      "Batch: 103988   Current total loss: 1.3007423 focal_loss: 0.34729627 IOU_loss: 0.34925443 centerness_loss: 0.5997053\n",
      "Batch: 103989   Current total loss: 1.2671257 focal_loss: 0.3244268 IOU_loss: 0.350922 centerness_loss: 0.5860873\n",
      "Batch: 103990   Current total loss: 1.3259232 focal_loss: 0.29272327 IOU_loss: 0.39903682 centerness_loss: 0.6271915\n",
      "Batch: 103991   Current total loss: 1.3930445 focal_loss: 0.338209 IOU_loss: 0.43602917 centerness_loss: 0.6133421\n",
      "Batch: 103992   Current total loss: 1.2494972 focal_loss: 0.2608133 IOU_loss: 0.38560888 centerness_loss: 0.59719783\n",
      "Batch: 103993   Current total loss: 1.2842932 focal_loss: 0.2901968 IOU_loss: 0.39448875 centerness_loss: 0.5950609\n",
      "Batch: 103994   Current total loss: 1.1951404 focal_loss: 0.28676808 IOU_loss: 0.31204036 centerness_loss: 0.5914088\n",
      "Batch: 103995   Current total loss: 1.2239757 focal_loss: 0.27937508 IOU_loss: 0.3436771 centerness_loss: 0.5951689\n",
      "Batch: 103996   Current total loss: 1.4226602 focal_loss: 0.39940035 IOU_loss: 0.41306356 centerness_loss: 0.60460097\n",
      "Batch: 103997   Current total loss: 1.2102807 focal_loss: 0.23686461 IOU_loss: 0.37235335 centerness_loss: 0.5973094\n",
      "Batch: 103998   Current total loss: 1.1720883 focal_loss: 0.29091918 IOU_loss: 0.2909637 centerness_loss: 0.5821825\n",
      "Batch: 103999   Current total loss: 1.2761879 focal_loss: 0.25182185 IOU_loss: 0.42181888 centerness_loss: 0.5998102\n",
      "Batch: 104000   Current total loss: 1.3061516 focal_loss: 0.30950323 IOU_loss: 0.38268945 centerness_loss: 0.6089955\n",
      "Model saved !!!\n",
      "Batch: 104001   Current total loss: 1.3585804 focal_loss: 0.34058934 IOU_loss: 0.40550494 centerness_loss: 0.6069821\n",
      "Batch: 104002   Current total loss: 1.4390274 focal_loss: 0.328541 IOU_loss: 0.49139836 centerness_loss: 0.61540776\n",
      "Batch: 104003   Current total loss: 1.1581906 focal_loss: 0.20691898 IOU_loss: 0.36167338 centerness_loss: 0.58287406\n",
      "Batch: 104004   Current total loss: 1.2054249 focal_loss: 0.26147524 IOU_loss: 0.35214713 centerness_loss: 0.588368\n",
      "Batch: 104005   Current total loss: 1.1947565 focal_loss: 0.25209603 IOU_loss: 0.35033435 centerness_loss: 0.5855265\n",
      "Batch: 104006   Current total loss: 1.2007971 focal_loss: 0.21329452 IOU_loss: 0.38722438 centerness_loss: 0.5960603\n",
      "Batch: 104007   Current total loss: 1.2180818 focal_loss: 0.31594026 IOU_loss: 0.31153 centerness_loss: 0.5840897\n",
      "Batch: 104008   Current total loss: 1.2907672 focal_loss: 0.33948517 IOU_loss: 0.35784313 centerness_loss: 0.58804274\n",
      "Batch: 104009   Current total loss: 1.2767547 focal_loss: 0.347678 IOU_loss: 0.33366412 centerness_loss: 0.59120065\n",
      "Batch: 104010   Current total loss: 1.3780081 focal_loss: 0.34994155 IOU_loss: 0.42251208 centerness_loss: 0.60300815\n",
      "Batch: 104011   Current total loss: 1.3610439 focal_loss: 0.2712152 IOU_loss: 0.47146505 centerness_loss: 0.6146472\n",
      "Batch: 104012   Current total loss: 1.3501434 focal_loss: 0.36417738 IOU_loss: 0.37728932 centerness_loss: 0.5995422\n",
      "Batch: 104013   Current total loss: 1.2264056 focal_loss: 0.2614812 IOU_loss: 0.36067438 centerness_loss: 0.59674346\n",
      "Batch: 104014   Current total loss: 1.2782778 focal_loss: 0.37280458 IOU_loss: 0.31904182 centerness_loss: 0.5775381\n",
      "Batch: 104015   Current total loss: 1.3826219 focal_loss: 0.2826778 IOU_loss: 0.48009276 centerness_loss: 0.61722565\n",
      "Batch: 104016   Current total loss: 1.254447 focal_loss: 0.31348586 IOU_loss: 0.3307611 centerness_loss: 0.60559803\n",
      "Batch: 104017   Current total loss: 1.541798 focal_loss: 0.4661724 IOU_loss: 0.45953834 centerness_loss: 0.61058336\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    train_writer = tf.summary.FileWriter(FLAGS.log_dir,sess.graph)\n",
    "    var_list = [var for var in tf.global_variables() if ('optimizer') not in var.name]\n",
    "    var_list_final = tf.global_variables()\n",
    "\n",
    "    saver = tf.train.Saver(var_list=var_list_final,max_to_keep=5)\n",
    "    saver_final = tf.train.Saver(var_list=var_list_final,max_to_keep=5)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n",
    "    if ckpt:\n",
    "        saver.restore(sess,ckpt)\n",
    "        print('Restore from the checkpoint {0}'.format(ckpt)) \n",
    "#         exclude = []\n",
    "#         variables_to_restore = tf.contrib.slim.get_variables_to_restore(exclude=exclude)\n",
    "#         tf.train.init_from_checkpoint(ckpt,\n",
    "#                                     {v.name.split(':')[0]: v for v in variables_to_restore})  \n",
    "    else:\n",
    "        print('Train ssd from start')\n",
    "        exclude = ['resnet_v2_50' + '/logits', 'global_step','output','output2',\"optimizer\",'postnorm']\n",
    "        variables_to_restore = tf.contrib.slim.get_variables_to_restore(exclude=exclude)\n",
    "        tf.train.init_from_checkpoint('./resnet_v2_50_2017_04_14/resnet_v2_50.ckpt',\n",
    "                                    {v.name.split(':')[0]: v for v in variables_to_restore})  \n",
    "    for i in range(start_step+1,10000000):\n",
    "        if(i%(5011//FLAGS.batch_size)==0):\n",
    "            annotation = get_path_and_annotation('/media/xinje/New Volume/VOC07&12/VOC2007/train/train_OCR.txt')\n",
    "            train_iter = read_data(annotation,FLAGS.batch_size,input_shape=(800,1024),is_random=False,is_crop=False)\n",
    "        image_batch,annotation_batch,cls_batch = next(train_iter)\n",
    "        #one hot for cls_batch\n",
    "        eye = np.eye(20)\n",
    "        eye = np.concatenate([eye,np.expand_dims(np.zeros_like(eye[0]),axis=0)])\n",
    "        cls_batch = eye[(cls_batch-1).astype(np.int32)].astype(np.float32)\n",
    "        \n",
    "        matched_true_boxes,matched_true_classes,matched_true_centerness = encode_boxes(annotation_batch,cls_batch,feature_size,stride)\n",
    "        feature_state = np.squeeze(matched_true_centerness!=0,axis=-1)\n",
    "        \n",
    "        feed_dict={inputs:image_batch,boxes:matched_true_boxes,classes:matched_true_classes,centerness:matched_true_centerness,state:feature_state}\n",
    "\n",
    "    \n",
    "        [_,train_summary,temp_loss,temp_focal_loss,temp_iou_loss,temp_centerness_loss,temp_centerness_output,temp_classes_output,temp_boxes_output] = sess.run([train_opt,merged_summary_op,total_losses,focal_losses,IOU_losses,centerness_losses,centerness_output_test,classes_output_test,boxes_output_test],feed_dict=feed_dict)\n",
    "        real_step = (i-start_step)//20+start_step\n",
    "        if((i-start_step)%20==0):\n",
    "            print('Batch: '+str(real_step)+'   Current total loss: '+str(temp_loss)+' focal_loss: '+str(temp_focal_loss)+' IOU_loss: '+str(temp_iou_loss)+' centerness_loss: '+str(temp_centerness_loss))\n",
    "#             break\n",
    "            train_writer.add_summary(train_summary, real_step)\n",
    "#             break\n",
    "        if((i-start_step)%1000==0 and i!=0):\n",
    "#             save model for training\n",
    "            saver_final.save(sess,os.path.join(FLAGS.checkpoint_dir,'FCOS-'),global_step=real_step) \n",
    "            #########################save model for inference#############################################\n",
    "#             constant_graph = convert_variables_to_constants(sess, sess.graph_def, ['boxes','scores','classes'])\n",
    "#             with tf.gfile.FastGFile('./model.pb', mode='wb') as f:\n",
    "#                 f.write(constant_graph.SerializeToString())\n",
    "            #####################################################################\n",
    "            print('Model saved !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# learning_rate = 1e-2\n",
    "# Si = tf.Variable(tf.constant(1.0,shape=[5,1],dtype=tf.float32), trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched_true_boxes,matched_true_classes,matched_true_centerness = encode_boxes(annotation_batch,cls_batch,feature_size,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(y_true, y_pred,anchor_state):\n",
    "    \"\"\"\n",
    "    Compute the focal loss given the target tensor and the predicted tensor.\n",
    "    As defined in https://arxiv.org/abs/1708.02002\n",
    "    Args\n",
    "        y_true: Tensor of target data from the generator with shape (B, N, num_classes).\n",
    "        y_pred: Tensor of predicted data from the network with shape (B, N, num_classes).\n",
    "    Returns\n",
    "        The focal loss of y_pred w.r.t. y_true.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"loss/focal\") as scope:\n",
    "        alpha=0.25\n",
    "        gamma=2.0\n",
    "        # compute the focal loss\n",
    "        location_state = anchor_state\n",
    "        labels = y_true\n",
    "        # alpha 参与用于调节正负样本的平衡问题\n",
    "        alpha_factor = tf.ones_like(labels) * alpha\n",
    "        alpha_factor = tf.where(tf.equal(labels, 1), alpha_factor, 1 - alpha_factor)\n",
    "        # focal_weight 用来使置信度较高容易的样本的 loss 比原来小, 而置信度低的难度大的 loss 变化不大\n",
    "        # (1 - 0.99) ** 2 = 1e-4, (1 - 0.9) ** 2 = 1e-2\n",
    "        focal_weight = tf.where(tf.equal(labels, 1), 1 - y_pred, y_pred)\n",
    "        focal_weight = alpha_factor * focal_weight ** gamma\n",
    "        # binary_crossentropy 是  -log(p) y=1 -log(1-p) y=others, 那么论文中统一的用 -log(pt) 来表示\n",
    "        #cls_loss = focal_weight * tf.nn.sigmoid_cross_entropy_with_logits(labels=labels,logits=y_pred)\n",
    "        cls_loss = focal_weight * tf.keras.backend.binary_crossentropy(target=labels,output=y_pred)\n",
    "        # compute the normalizer: the number of positive anchors\n",
    "        normalizer = tf.where(tf.equal(location_state, 1))\n",
    "        normalizer = tf.cast(tf.shape(normalizer)[0], tf.float32)\n",
    "        normalizer = tf.maximum(1.0, normalizer)\n",
    "        loss = tf.reduce_sum(cls_loss) / normalizer\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iou_loss(y_true, y_pred,location_state,centerness):\n",
    "    with tf.variable_scope(\"loss/iou\") as scope:\n",
    "        # pos location\n",
    "        indices = tf.where(tf.equal(location_state, 1))\n",
    "    #     print(indices.shape)\n",
    "        if tf.size(indices) == 0:\n",
    "            return tf.constant(0.0)\n",
    "        y_regr_pred = tf.gather_nd(y_pred, indices)\n",
    "    #     print(y_regr_pred.shape)\n",
    "        y_regr_true = tf.gather_nd(y_true, indices)\n",
    "        y_centerness_true = tf.gather_nd(centerness,indices)\n",
    "\n",
    "        # (num_pos, )\n",
    "        pred_top = y_regr_pred[:, 0]\n",
    "        pred_bottom = y_regr_pred[:, 1]\n",
    "        pred_left = y_regr_pred[:, 2]\n",
    "        pred_right = y_regr_pred[:, 3]\n",
    "\n",
    "        # (num_pos, )\n",
    "        target_top = y_regr_true[:, 0]\n",
    "        target_bottom = y_regr_true[:, 1]\n",
    "        target_left = y_regr_true[:, 2]\n",
    "        target_right = y_regr_true[:, 3]\n",
    "\n",
    "        target_area = (target_left + target_right) * (target_top + target_bottom)\n",
    "        pred_area = (pred_left + pred_right) * (pred_top + pred_bottom)\n",
    "        w_intersect = tf.minimum(pred_left, target_left) + tf.minimum(pred_right, target_right)\n",
    "        h_intersect = tf.minimum(pred_bottom, target_bottom) + tf.minimum(pred_top, target_top)\n",
    "\n",
    "        g_w_intersect = tf.maximum(pred_left, target_left) + tf.maximum(pred_right, target_right)\n",
    "        g_h_intersect = tf.maximum(pred_bottom, target_bottom) + tf.maximum(pred_top, target_top)\n",
    "        ac_union = g_w_intersect * g_h_intersect\n",
    "        euclidean_distance = tf.pow((-target_left + target_right)/2 -(-pred_left + pred_right)/2,2) + tf.pow((-target_top + target_bottom)/2 -(-pred_top + pred_bottom)/2,2)\n",
    "        area_intersect = w_intersect * h_intersect\n",
    "        area_union = target_area + pred_area - area_intersect\n",
    "        ious = (area_intersect) / (area_union+1e-8)\n",
    "        dious = 1-ious+(euclidean_distance/tf.pow(ac_union+1e-8,2))\n",
    "        # (num_pos, )\n",
    "        #losses = tf.reduce_sum(losses * y_centerness_true) / (tf.reduce_sum(y_centerness_true) + 1e-6)\n",
    "\n",
    "        losses =  tf.reduce_mean(dious)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_batch,annotation_batch,cls_batch = next(train_iter)\n",
    "# #one hot for cls_batch\n",
    "# eye = np.eye(20)\n",
    "# eye = np.concatenate([eye,np.expand_dims(np.zeros_like(eye[0]),axis=0)])\n",
    "# cls_batch = eye[(cls_batch-1).astype(np.int32)]\n",
    "\n",
    "# matched_true_boxes,matched_true_classes,matched_true_centerness = encode_boxes(annotation_batch,cls_batch,feature_size,stride)\n",
    "# feature_state = []\n",
    "# for m_t_ctn in matched_true_centerness:\n",
    "#     feature_state.append((m_t_ctn!=0).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum((matched_true_boxes[1]<0).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t= encode_boxes(annotation_batch,cls_batch,feature_size,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(FLAGS.batch_size):\n",
    "#     plt.hlines(annotation_batch[i,:,0]*800,annotation_batch[i,:,1]*1024,annotation_batch[i,:,3]*1024,'r')\n",
    "#     plt.hlines(annotation_batch[i,:,2]*800,annotation_batch[i,:,1]*1024,annotation_batch[i,:,3]*1024,'r')\n",
    "#     plt.vlines(annotation_batch[i,:,1]*1024,annotation_batch[i,:,0]*800,annotation_batch[i,:,2]*800,'r')\n",
    "#     plt.vlines(annotation_batch[i,:,3]*1024,annotation_batch[i,:,0]*800,annotation_batch[i,:,2]*800,'r')\n",
    "#     plt.imshow(image_batch[i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation_batch[0]*1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched_true_boxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image_index in range(FLAGS.batch_size):\n",
    "#     for layer_index in range(5):\n",
    "#         true_boxes = matched_true_boxes[layer_index][image_index]\n",
    "#         true_classes = matched_true_classes[layer_index][image_index]\n",
    "#         true_boxes = true_boxes.reshape(feature_size[layer_index][0],feature_size[layer_index][1],4)\n",
    "#         true_classes = true_classes.reshape(feature_size[layer_index][0],feature_size[layer_index][1],20)\n",
    "#         print(np.sum(true_boxes!=0))\n",
    "#         print(true_boxes.shape)\n",
    "#         for i in range(feature_size[layer_index][0]):\n",
    "#             for j in range(feature_size[layer_index][1]):\n",
    "#                 y_center= (i+0.5)\n",
    "#                 x_center= (j+0.5)\n",
    "#                 if(np.sum(true_boxes[i,j]!=0)!=0):\n",
    "#                     xmin = (x_center-(true_boxes[i,j,2]*true_boxes.shape[1]))*stride[layer_index]\n",
    "#                     xmax = ((true_boxes[i,j,3]*true_boxes.shape[1])+x_center)*stride[layer_index]\n",
    "#                     ymin = (y_center-(true_boxes[i,j,0]*true_boxes.shape[0]))*stride[layer_index]\n",
    "#                     ymax = ((true_boxes[i,j,1]*true_boxes.shape[0])+y_center)*stride[layer_index]\n",
    "#         #             if((xmin>=0)and(ymin>0)and(xmax>0)and(ymax>0)):\n",
    "#                     plt.hlines(ymin,xmin,xmax,'r')\n",
    "#                     plt.hlines(ymax,xmin,xmax,'r')\n",
    "#                     plt.vlines(xmin,ymin,ymax,'r')\n",
    "#                     plt.vlines(xmax,ymin,ymax,'r')\n",
    "#                     print(ymin,xmin,ymax,xmax)\n",
    "#                     print(true_classes[i,j])\n",
    "#                     plt.imshow(image_batch[image_index])\n",
    "#                     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(matched_true_boxes[3]>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyramid_dict = resnet_base(inputs,'resnet_v1_50',is_training = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# config = tf.ConfigProto(allow_soft_placement=True)\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "# config.gpu_options.allow_growth = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_centerness_output = temp_centerness_output.reshape(-1,1)\n",
    "temp_classes_output = temp_classes_output.reshape(-1,20)\n",
    "temp_boxes_output = temp_boxes_output.reshape(-1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (temp_classes_output *temp_centerness_output)>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_boxes_output[mask[:,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_classes_output[mask[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_list = []\n",
    "for i in range(5):\n",
    "    offset = np.math.floor(stride[i]/2)\n",
    "    y_center_mapping = np.array([(j*stride[i]+offset) for j in range(feature_size[i][0])])/FLAGS.image_height\n",
    "    x_center_mapping = np.array([(j*stride[i]+offset) for j in range(feature_size[i][1])])/FLAGS.image_width\n",
    "    y_center_mapping = np.expand_dims(np.tile(np.expand_dims(y_center_mapping,axis=-1),[1,feature_size[i][1]]),axis=-1)\n",
    "    x_center_mapping = np.expand_dims(np.tile(np.expand_dims(x_center_mapping,axis=0),[feature_size[i][0],1]),axis=-1)\n",
    "    center = np.concatenate([y_center_mapping,x_center_mapping],axis=-1).reshape(FLAGS.batch_size,(feature_size[i][0]*feature_size[i][1]),2)\n",
    "    center_list.append(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_list = np.squeeze((np.concatenate(center_list,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(center_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_center_list = np.squeeze(center_list)[mask[:,18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymin = (selected_center_list[:,0]-(temp_boxes_output[mask[:,18]])[:,0])*800\n",
    "ymax = (selected_center_list[:,0]+(temp_boxes_output[mask[:,18]])[:,0])*800\n",
    "xmin = (selected_center_list[:,1]-(temp_boxes_output[mask[:,18]])[:,1])*1024\n",
    "xmax = (selected_center_list[:,1]+(temp_boxes_output[mask[:,18]])[:,1])*1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(temp_boxes_output[mask[:,18]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hlines(ymin,xmin,xmax,'r')\n",
    "# plt.hlines(ymax,xmin,xmax,'r')\n",
    "# plt.vlines(xmin,ymin,ymax,'r')\n",
    "# plt.vlines(xmax,ymin,ymax,'r')\n",
    "plt.imshow(image_batch[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_boxes_output[mask[:,18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze(matched_true_boxes)[mask[:,18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,b,l,r = np.split(boxes_3,indices_or_sections=4,axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_3[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tblr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_classes_output = np.concatenate(temp_classes_output,axis=1).reshape(-1,20)\n",
    "temp_centerness_output = np.concatenate(temp_centerness_output,axis=1).reshape(-1,1)\n",
    "temp_boxes_output = np.concatenate(temp_boxes_output,axis=1).reshape(-1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((temp_classes_output*temp_centerness_output)>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_boxes_output[mask[:,18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
